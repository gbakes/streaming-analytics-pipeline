connectors:
  postgres-source:
    name: "postgres-connector"
    config:
      connector.class: "io.debezium.connector.postgresql.PostgresConnector"
      tasks.max: "1"
      database.hostname: "postgres"
      database.port: "${POSTGRES_PORT}"
      database.user: "${POSTGRES_USER}"
      database.password: "${POSTGRES_PASSWORD}"
      database.dbname: "${POSTGRES_DB}"
      database.server.name: "postgres-server"
      topic.prefix: "postgres-server"
      table.include.list: "public.customers,public.products,public.orders,public.order_items"
      plugin.name: "pgoutput"
      transforms: "unwrap"
      transforms.unwrap.type: "io.debezium.transforms.ExtractNewRecordState"
      transforms.unwrap.drop.tombstones: "false"
      transforms.unwrap.delete.handling.mode: "rewrite"
      slot.name: "${DEBEZIUM_SLOT_NAME}"
      
      publication.name: "dbz_publication"
      
      snapshot.mode: "always"
      snapshot.fetch.size: 10240
      
      tombstones.on.delete: "true"
      provide.transaction.metadata: "true"
      
      key.converter: "org.apache.kafka.connect.json.JsonConverter"
      key.converter.schemas.enable: "true"
      value.converter: "org.apache.kafka.connect.json.JsonConverter"
      value.converter.schemas.enable: "true"
      
      transforms: "unwrap"
      transforms.unwrap.type: "io.debezium.transforms.ExtractNewRecordState"
      transforms.unwrap.drop.tombstones: "false"
      transforms.unwrap.delete.handling.mode: "rewrite"
      
      max.batch.size: 1024
      max.queue.size: 8192
      poll.interval.ms: 1000
      include.schema.changes: "true"

  customers-s3-sink:
    name: "customers-s3-sink"
    config:
      connector.class: "io.confluent.connect.s3.S3SinkConnector"
      tasks.max: "1"
      topics: "postgres-server.public.customers"
      s3.bucket.name: "retail-data"
      s3.part.size: 5242880
      s3.endpoint: "http://minio:9000"
      aws.access.key.id: "${MINIO_ACCESS_KEY}"
      aws.secret.access.key: "${MINIO_SECRET_KEY}"
      storage.class: "io.confluent.connect.s3.storage.S3Storage"
      format.class: "io.confluent.connect.s3.format.json.JsonFormat"
      partitioner.class: "io.confluent.connect.storage.partitioner.TimeBasedPartitioner"
      partition.duration.ms: 3600000
      path.format: "'customers'/yyyy/MM/dd/HH"
      locale: "US"
      timezone: "UTC"
      timestamp.extractor: "Record"
      timestamp.field: "created_at"
      flush.size: "1000"
      rotate.interval.ms: "60000"
      s3.path.style.access: "true"
      s3.proxy.url: "http://minio:9000"
      s3.region: ""
      store.url: "http://minio:9000"

  products-s3-sink:
    name: "products-s3-sink"
    config:
      connector.class: "io.confluent.connect.s3.S3SinkConnector"
      tasks.max: "1"
      topics: "postgres-server.public.products"
      s3.bucket.name: "retail-data"
      s3.part.size: 5242880
      s3.endpoint: "http://minio:9000"
      aws.access.key.id: "${MINIO_ACCESS_KEY}"
      aws.secret.access.key: "${MINIO_SECRET_KEY}"
      storage.class: "io.confluent.connect.s3.storage.S3Storage"
      format.class: "io.confluent.connect.s3.format.json.JsonFormat"
      partitioner.class: "io.confluent.connect.storage.partitioner.TimeBasedPartitioner"
      partition.duration.ms: 3600000
      path.format: "'products'/yyyy/MM/dd/HH"
      locale: "US"
      timezone: "UTC"
      timestamp.extractor: "Record"
      timestamp.field: "created_at"
      flush.size: "500"
      rotate.interval.ms: "60000"
      s3.path.style.access: "true"
      s3.proxy.url: "http://minio:9000"
      s3.region: ""
      store.url: "http://minio:9000"

  orders-s3-sink:
    name: "orders-s3-sink"
    config:
      connector.class: "io.confluent.connect.s3.S3SinkConnector"
      tasks.max: "1"
      topics: "postgres-server.public.orders"
      s3.bucket.name: "retail-data"
      s3.part.size: 5242880
      s3.endpoint: "http://minio:9000"
      aws.access.key.id: "${MINIO_ACCESS_KEY}"
      aws.secret.access.key: "${MINIO_SECRET_KEY}"
      storage.class: "io.confluent.connect.s3.storage.S3Storage"
      format.class: "io.confluent.connect.s3.format.json.JsonFormat"
      partitioner.class: "io.confluent.connect.storage.partitioner.TimeBasedPartitioner"
      partition.duration.ms: 3600000
      path.format: "'orders'/yyyy/MM/dd/HH"
      locale: "US"
      timezone: "UTC"
      timestamp.extractor: "Record"
      timestamp.field: "order_date"
      flush.size: "750"
      rotate.interval.ms: "60000"
      s3.path.style.access: "true"
      s3.proxy.url: "http://minio:9000"
      s3.region: ""
      store.url: "http://minio:9000"

  order-items-s3-sink:
    name: "order-items-s3-sink"
    config:
      connector.class: "io.confluent.connect.s3.S3SinkConnector"
      tasks.max: "1"
      topics: "postgres-server.public.order_items"
      s3.bucket.name: "retail-data"
      s3.part.size: 5242880
      s3.endpoint: "http://minio:9000"
      aws.access.key.id: "${MINIO_ACCESS_KEY}"
      aws.secret.access.key: "${MINIO_SECRET_KEY}"
      storage.class: "io.confluent.connect.s3.storage.S3Storage"
      format.class: "io.confluent.connect.s3.format.json.JsonFormat"
      partitioner.class: "io.confluent.connect.storage.partitioner.TimeBasedPartitioner"
      partition.duration.ms: 3600000
      path.format: "'order_items'/yyyy/MM/dd/HH"
      locale: "US"
      timezone: "UTC"
      timestamp.extractor: "Record"
      timestamp.field: "created_at"
      flush.size: "1000"
      rotate.interval.ms: "60000"
      s3.path.style.access: "true"
      s3.proxy.url: "http://minio:9000"
      s3.region: ""
      store.url: "http://minio:9000"
